#!/bin/env python

import datetime
import os
import re
import sys
from ScarScript import ScarScript

class jobhist(ScarScript):
  """
  jobhist - report past/present running batch jobs

  jobhist [-h -v] [--account=pat] [--at=time] [--csv=y/n] [--earliest=time]
          [--latest=time] [--node=pat] [--user=pat] [file ...]

  This script reports the user, starting and ending times, and run nodes of
  batch jobs.

    --account
      Show only jobs charged to an account that matches the specified pattern.

    --at
      Show only jobs running at the given time; equivalent to --earliest=time
      --latest=time

    --csv
      Indicates whether to produce tabular ('n') or comma-separated ('y')
      output.  The default is 'n'.

    --earliest
      Display no jobs that finished before the given time.  Time has the
      format YYYY-MM-DD-HH:MM:SS, where any leading prefix can be specified
      (e.g., --earliest=2010-04-13 to filter jobs that ran before that date).

    -h
      Show this information, then exit.

    --latest
      Show no jobs that started before the given time.  See --earliest for
      the time format.

    --node
      Report only those jobs that ran on a node that matches the specified
      pattern.

    --user
      Show only jobs belonging to a user that matches the specified pattern.

    -v
      Print version, then exit

    file ...
      List of files from which to read messages.  '-' indicates stdin.
      Default /var/spool/torque/server_logs/<current date>.
  """

  JOB_FORMAT = '%-12.12s %-15.15s %-15.15s %-5.5s %-15.15s %-19s %-19s %-8s %-19s %-8s'
  JOB_CSV = '%s,%s,%s,%s,%s,%s,%s,%s,%s,%s'
  QUEUE_FORMAT = '%-15.15s %10s %10s %10s %10s %10s %8s %8s'
  QUEUE_CSV = '%s,%s,%s,%s,%s,%s,%s,%s'
  VERSION = '1.0'

  def __init__(self):
    """Class constructor; pass the sys.argv as the parameter."""

    (options, args) = self.parseArgs([
      '--account:s', '--at:s', '--csv:s', '--earliest:s', '--latest:s',
      '--node:s', '--user:s'
    ])
    if len(args) == 0:
      args.append(
        sorted(os.listdir('/var/spool/torque/server_priv/accounting'))[-1]
      )
    self.accountFilter = None
    if options.account:
      self.accountFilter = options.account
    self.csv = 'n'
    if options.csv:
      self.csv = options.csv
    self.earliest = None
    if options.earliest:
      self.earliest = parseTime(options.earliest)
    self.latest = None
    if options.latest:
      self.latest = parseTime(options.latest)
    self.nodeFilter = None
    if options.node:
      self.nodeFilter = options.node
    self.userFilter = None
    if options.user:
      self.userFilter = options.user
    if options.at:
      self.earliest = self.latest = parseTime(options.at)

    firstDatetime = None
    lastDatetime = None
    jobAttributes = {}
    jobTimes = {}
    queueStats = {}

    for file in args:

      if file == '-':
        messages = sys.stdin
      else:
        if not '/' in file:
          file = '/var/spool/torque/server_priv/accounting/' + file
        messages = open(file, 'r')
        if not messages:
          sys.stderr.write("Open %s failed\n" % file)
          sys.exit(1)

      # Parse the input records
      for message in messages:

        # Accounting entry format:
        # MM/DD/YY HH:MM:SS;step;jobid;attr=value ...
        message = message.rstrip()
        pieces = message.split(';', 3)
        if len(pieces) != 4 or not ' ' in pieces[0]:
          continue

        (step, jobid, attrs) = (pieces[1], pieces[2], pieces[3])
        # Strip hostname from jobid
        jobid = jobid.split('.')[0]

        # Initialize job cancel/end/queue/start times and attribute list
        if not jobTimes.has_key(jobid):
          jobTimes[jobid] = {'A': None, 'D': None, 'E':None, 'Q':None, 'S':None}
        if not jobAttributes.has_key(jobid):
          jobAttributes[jobid] = {}

        jobTimes[jobid][step] = parseTime(pieces[0])
        # {first,last}Datetime hold the earliest/latest timestamps over all
        # processed records
        if not firstDatetime or jobTimes[jobid][step] < firstDatetime:
          firstDatetime = jobTimes[jobid][step]
        if not lastDatetime or jobTimes[jobid][step] > lastDatetime:
          lastDatetime = jobTimes[jobid][step]
        for attr in attrs.split(' '):
          if not '=' in attr:
            continue
          (attr, value) = attr.split('=', 1)
          jobAttributes[jobid][attr] = value

      messages.close()

    # Print per-job statistics
    jobFormat = jobhist.JOB_FORMAT
    if self.csv == 'y':
      jobFormat = jobhist.JOB_CSV
    nodePpnIncrements = {}
    print jobFormat % (
      'JOB', 'USER', 'QUEUE', 'SIZE', 'HOST', 'QUEUED', 'START', 'WAIT', 'END',
      'RUN'
    )
    for jobid in sorted(jobTimes.keys(), key=lambda jobid: int(jobid.split('[')[0])):

      (jobStarted, jobQueued, jobFinished) = (
        jobTimes[jobid]['S'], jobTimes[jobid]['Q'], jobTimes[jobid]['E']
      )
      if jobTimes[jobid]['A']:
        jobFinished = jobTimes[jobid]['A']
      elif jobTimes[jobid]['D']:
        jobFinished = jobTimes[jobid]['D']
      # Pick out job attributes we care about ...
      attrs = jobAttributes[jobid]
      (jobAccount, jobNodes, jobQueue, jobNodeCount, jobPpn, jobUser) = (
        'None', 'None', 'None', '?', '?', 'None'
      )
      if 'account' in attrs:
        jobAccount = attrs['account']
      if 'exec_host' in attrs:
        jobNodes = attrs['exec_host']
      if 'Resource_List.neednodes' in attrs:
        matchInfo = re.search('ppn=(\d+)', attrs['Resource_List.neednodes'])
        if matchInfo:
          jobPpn = matchInfo.group(1)
      if 'Resource_List.nodect' in attrs:
        jobNodeCount = attrs['Resource_List.nodect']
      if 'queue' in attrs:
        jobQueue = attrs['queue']
      if 'user' in attrs:
        jobUser = attrs['user']
      elif 'requestor' in attrs:
        jobUser = attrs['requestor'].split('@')[0]
  
      # ... and test against any user filters
      if self.accountFilter and not re.search(self.accountFilter, jobAccount):
        continue
      if self.earliest and (not jobFinished or jobFinished < self.earliest):
        continue
      if self.latest and (not jobStarted or jobStarted > self.latest):
        continue
      if self.nodeFilter and not re.search(self.nodeFilter, jobNodes):
        continue
      if self.userFilter and not re.search(self.userFilter, jobUser):
        continue

      jobProcsPerNode = {}
      jobFirstNode = 'None'
      jobOtherNodes = ''
      if jobNodes != 'None':
        # Determine number of processors used on each node the job used
        for node in jobNodes.split('+'):
          # Separate node name from processor number
          node = node.split('/')[0]
          if not node in jobProcsPerNode:
            jobProcsPerNode[node] = 0
          jobProcsPerNode[node] += 1
        for node in sorted(jobProcsPerNode):
          if jobFirstNode == 'None':
            jobFirstNode = "%sx%d" % (node, jobProcsPerNode[node])
          else:
            jobOtherNodes += "%sx%d+" % (node, jobProcsPerNode[node])
          # Retain ppn usage change for later per-node report
          if not node in nodePpnIncrements:
            nodePpnIncrements[node] = []
          if jobStarted:
            nodePpnIncrements[node].append({'ts':jobStarted, 'amount':jobProcsPerNode[node]})
          else:
            nodePpnIncrements[node].append({'ts':firstDatetime, 'amount':jobProcsPerNode[node]})
          if jobFinished:
            nodePpnIncrements[node].append({'ts':jobFinished, 'amount':-jobProcsPerNode[node]})
        jobOtherNodes = jobOtherNodes.rstrip('+')

      (jobRunDuration, jobWaitDuration) = (None, None)
      if jobQueued and jobStarted:
        jobWaitDuration = jobStarted - jobQueued
      if jobStarted and jobFinished:
        jobRunDuration = jobFinished - jobStarted
      
      if self.csv == 'y' and jobOtherNodes != '':
        jobFirstNode += '+' + jobOtherNodes
        jobOtherNodes = ''
      if jobNodeCount == '?' and len(jobProcsPerNode.keys()) > 0:
        jobNodeCount = len(jobProcsPerNode.keys())
      if jobPpn == '?' and len(jobProcsPerNode.keys()) > 0:
        jobPpn = jobProcsPerNode[jobProcsPerNode.keys()[0]]
      jobText = jobFormat % (
        jobid, jobUser, jobQueue, "%sx%s" % (jobNodeCount, jobPpn),
        jobFirstNode, jobQueued, jobStarted, deltaString(jobWaitDuration), jobFinished,
        deltaString(jobRunDuration)
      )
      if jobTimes[jobid]['A'] or jobTimes[jobid]['D']:
        jobText += ' (*)'
      if jobOtherNodes != '':
        jobText += '\n+ ' + jobOtherNodes
      print jobText

      # Retain job queue information for later reporting
      if not queueStats.has_key(jobQueue):
        queueStats[jobQueue] = {
          'jobCount':0, 'queuedCount':0, 'startedCount':0, 'finishedCount':0,
          'canceledCount':0, 'waitCount':0, 'waitTotal':datetime.timedelta(),
          'runCount':0, 'runTotal':datetime.timedelta()
        }
      if not queueStats.has_key('ALL'):
        queueStats['ALL'] = {
          'jobCount':0, 'queuedCount':0, 'startedCount':0, 'finishedCount':0,
          'canceledCount':0, 'waitCount':0, 'waitTotal':datetime.timedelta(),
          'runCount':0, 'runTotal':datetime.timedelta()
        }
      queueStats[jobQueue]['jobCount'] += 1
      queueStats['ALL']['jobCount'] += 1
      if jobQueued:
        queueStats[jobQueue]['queuedCount'] += 1
        queueStats['ALL']['queuedCount'] += 1
      if jobStarted:
        queueStats[jobQueue]['startedCount'] += 1
        queueStats['ALL']['startedCount'] += 1
      if jobFinished:
        queueStats[jobQueue]['finishedCount'] += 1
        queueStats['ALL']['finishedCount'] += 1
      if jobWaitDuration:
        queueStats[jobQueue]['waitCount'] += 1
        queueStats[jobQueue]['waitTotal'] += jobWaitDuration
        queueStats['ALL']['waitCount'] += 1
        queueStats['ALL']['waitTotal'] += jobWaitDuration
      if jobRunDuration:
        queueStats[jobQueue]['runCount'] += 1
        queueStats[jobQueue]['runTotal'] += jobRunDuration
        queueStats['ALL']['runCount'] += 1
        queueStats['ALL']['runTotal'] += jobRunDuration
      if jobTimes[jobid]['A'] or jobTimes[jobid]['D']:
        queueStats[jobQueue]['canceledCount'] += 1
        queueStats['ALL']['canceledCount'] += 1

    # Print per-queue summary statistics
    queueFormat = jobhist.QUEUE_FORMAT
    if self.csv == 'y':
      queueFormat = jobhist.QUEUE_CSV
    print queueFormat % (
      'QUEUE', 'JOBS', 'QUEUED', 'STARTED', 'FINISHED', 'CANCELED', 'AVGWAIT',
      'AVGRUN'
    )
    for queue in sorted(queueStats):
      (queueRunAvg, queueWaitAvg) = ('N/A', 'N/A')
      if queueStats[queue]['runCount'] > 0:
        queueRunAvg = datetime.timedelta(
          0, deltaSecs(queueStats[queue]['runTotal']) /
             queueStats[queue]['runCount']
        )
      if queueStats[queue]['waitCount'] > 0:
        queueWaitAvg = datetime.timedelta(
          0, deltaSecs(queueStats[queue]['waitTotal']) /
             queueStats[queue]['waitCount']
        )
      print queueFormat % (
        queue, queueStats[queue]['jobCount'], queueStats[queue]['queuedCount'],
        queueStats[queue]['startedCount'], queueStats[queue]['finishedCount'],
        queueStats[queue]['canceledCount'], queueWaitAvg, queueRunAvg
      )

    # Print per-node summary statistics
    reportSecs = deltaSecs(lastDatetime - firstDatetime)
    totalProcSecsAvailable = 0
    totalProcSecsUsed = 0
    for node in sorted(nodePpnIncrements):
      nodeProcs = 16
      if 'gpu' in node:
        nodeProcs = 12
      if 'pdafm' in node:
        nodeProcs = 32
      nodeProcSecsAvailable = nodeProcs * reportSecs
      nodeProcsInUse = 0
      priorTs = None
      nodeProcSecsUsed = 0
      debug = '%s:' % node
      for increment in sorted(nodePpnIncrements[node], key=lambda item: item['ts']):
        ts = increment['ts']
        if priorTs:
          nodeProcSecsUsed += nodeProcsInUse * deltaSecs(ts - priorTs)
        nodeProcsInUse += increment['amount']
        priorTs = ts
        debug += " %s/%d" % (ts, nodeProcsInUse)
      # print debug
      print "%s: %d%%" % (node, (nodeProcSecsUsed * 1.0) / nodeProcSecsAvailable * 100)
      totalProcSecsAvailable += nodeProcSecsAvailable
      totalProcSecsUsed += nodeProcSecsUsed
    if totalProcSecsAvailable > 0:
      print "%s: %d%%" % ("Average", (totalProcSecsUsed * 1.0) / totalProcSecsAvailable * 100)

def deltaString(d):
  """Returns text for a timedelta in better format than the default."""
  if d == None:
    return 'None'
  seconds = deltaSecs(d)
  result = str(int(seconds / 86400))
  seconds %= 86400
  result += ":%02d" % int(seconds / 3600)
  seconds %= 3600
  result += ":%02d:%02d" % (int(seconds / 60), seconds % 60)
  return re.sub(r'^0', '', re.sub(r'^(0+:)', '', result))

def deltaSecs(d):
  """Returns the total seconds represented by a timedelta."""
  return d.seconds + d.days * 24 * 60 * 60

def parseTime(t):
  """Returns a datetime represented by a string."""
  (year, month, dayOfMonth, hour, minute, second) = (2000, 1, 1, 0, 0, 0)
  if ' ' in t:
    # From accounting file MM/DD/YY HH:MM:SS
    (date, time) = t.split(' ', 1)
    (month, dayOfMonth, year) = date.split('/')
    (hour, minute, second) = time.split(':', 2)
  else:
    # From options file YYYY[-MM[-DD[-HH[:MM[:SS]]]]]
    pieces = t.split('-')
    year = pieces[0]
    if len(pieces) > 1:
      month = pieces[1]
    if len(pieces) > 2:
      dayOfMonth = pieces[2]
    if len(pieces) > 3:
      pieces = pieces[3].split(':')
      hour = pieces[0]
      if len(pieces) > 1:
        minute = pieces[1]
      if len(pieces) > 2:
        minute = pieces[2]
  return datetime.datetime(int(year), int(month), int(dayOfMonth), int(hour), int(minute), int(second))

jobhist()
